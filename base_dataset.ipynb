{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8efb8459-33ee-40ec-9061-b7ba2f2adfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b4cfbf5-6df2-4424-95c5-1f90dada961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datanames = ['toys-split','sports-split','beauty-split']\n",
    "dataname = datanames[0]\n",
    "data_root = f\"/data2/wangzhongren/taolin_project/dataset/{dataname}\"\n",
    "output_root = f\"/data2/wangzhongren/taolin_project/data/{dataname}\"\n",
    "sample_filename = f\"{dataname}.item\"\n",
    "dataset_types = ['train','valid','test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92cf0a49-5794-478d-a368-396fd4600d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>sales_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0375829695</td>\n",
       "      <td>Home &amp; Kitchen</td>\n",
       "      <td>Dr. Seuss</td>\n",
       "      <td>'Toys &amp; Games', 'Puzzles', 'Jigsaw Puzzles'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0439855896</td>\n",
       "      <td>Toys &amp; Games</td>\n",
       "      <td>Rock Ridge</td>\n",
       "      <td>'Toys &amp; Games', 'Novelty &amp; Gag Toys', 'Magic K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0439893577</td>\n",
       "      <td>missing</td>\n",
       "      <td>Scholastic</td>\n",
       "      <td>'Toys &amp; Games', 'Pretend Play', 'Dress Up &amp; Pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id      sales_type       brand  \\\n",
       "0  0375829695  Home & Kitchen   Dr. Seuss   \n",
       "1  0439855896    Toys & Games  Rock Ridge   \n",
       "2  0439893577         missing  Scholastic   \n",
       "\n",
       "                                          categories  \n",
       "0        'Toys & Games', 'Puzzles', 'Jigsaw Puzzles'  \n",
       "1  'Toys & Games', 'Novelty & Gag Toys', 'Magic K...  \n",
       "2  'Toys & Games', 'Pretend Play', 'Dress Up & Pr...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对item数据集的特征列进行处理，包括填充缺失值，对类别的分割\n",
    "feat_keys = ['item_id', 'sales_type', 'brand','categories']\n",
    "sample_path = os.path.join(data_root,sample_filename)\n",
    "df_feat = pd.read_csv(sample_path, sep='\\t', header=0)\n",
    "df_feat.columns = [col.split(\":\")[0] for col in df_feat.keys()]\n",
    "df_feat= df_feat[feat_keys]\n",
    "# 不对类目特征做额外处理\n",
    "# for i in range(3):\n",
    "#     df_feat[f'category_{i+1}'] = df_feat['categories'].str.split(',').str.get(i).str.strip().fillna('Unknown')\n",
    "# df_feat = df_feat.drop(columns=['categories'])\n",
    "df_feat['sales_type'] = df_feat['sales_type'].fillna(\"missing\")\n",
    "df_feat[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "315bd360-ce4b-4acc-b7b8-cccd6dad0855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>label</th>\n",
       "      <th>dataset_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AYVR1MQCTNU5D</td>\n",
       "      <td>0375829695</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3CJHKFHHQJP2K</td>\n",
       "      <td>0375829695</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3638FINP26E8N</td>\n",
       "      <td>0375829695</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id     item_id  label dataset_type\n",
       "0   AYVR1MQCTNU5D  0375829695      1        train\n",
       "1  A3CJHKFHHQJP2K  0375829695      0        train\n",
       "2  A3638FINP26E8N  0375829695      0        train"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对训练用数据集进行初步处理，label,列名等等，检查是否有空值\n",
    "df_all = pd.DataFrame()\n",
    "for dataset_type in dataset_types:\n",
    "    data_filename = f\"{dataname}.{dataset_type}.inter\"\n",
    "    data_path = f\"{data_root}/{data_filename}\"\n",
    "    df_data = pd.read_csv(data_path, sep='\\t', header=0)\n",
    "    df_data.columns = [col.split(\":\")[0] for col in df_data.keys()]\n",
    "    df_data['label'] = (df_data['rating']>3).astype(int)\n",
    "    df_data = df_data.drop(columns = ['rating'])\n",
    "    df_data = df_data.drop(columns = ['timestamp'])\n",
    "    df_data['dataset_type'] = dataset_type\n",
    "    df_all = pd.concat([df_all, df_data], ignore_index=True)\n",
    "df_all[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3aa8ac1b-9f59-479d-9802-21c60321c621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>label</th>\n",
       "      <th>dataset_type</th>\n",
       "      <th>sales_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AYVR1MQCTNU5D</td>\n",
       "      <td>0375829695</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>Home &amp; Kitchen</td>\n",
       "      <td>Dr. Seuss</td>\n",
       "      <td>'Toys &amp; Games', 'Puzzles', 'Jigsaw Puzzles'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3CJHKFHHQJP2K</td>\n",
       "      <td>0375829695</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>Home &amp; Kitchen</td>\n",
       "      <td>Dr. Seuss</td>\n",
       "      <td>'Toys &amp; Games', 'Puzzles', 'Jigsaw Puzzles'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3638FINP26E8N</td>\n",
       "      <td>0375829695</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>Home &amp; Kitchen</td>\n",
       "      <td>Dr. Seuss</td>\n",
       "      <td>'Toys &amp; Games', 'Puzzles', 'Jigsaw Puzzles'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id     item_id  label dataset_type      sales_type      brand  \\\n",
       "0   AYVR1MQCTNU5D  0375829695      1        train  Home & Kitchen  Dr. Seuss   \n",
       "1  A3CJHKFHHQJP2K  0375829695      0        train  Home & Kitchen  Dr. Seuss   \n",
       "2  A3638FINP26E8N  0375829695      0        train  Home & Kitchen  Dr. Seuss   \n",
       "\n",
       "                                    categories  \n",
       "0  'Toys & Games', 'Puzzles', 'Jigsaw Puzzles'  \n",
       "1  'Toys & Games', 'Puzzles', 'Jigsaw Puzzles'  \n",
       "2  'Toys & Games', 'Puzzles', 'Jigsaw Puzzles'  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把item特征混合到训练集中\n",
    "df_all_merged = pd.merge(df_all,df_feat,on='item_id',how='left')\n",
    "df_all_merged[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1060f351",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_ids_path = os.path.join(data_root, \"item_id.pt\")\n",
    "item_ids_list = torch.load(item_ids_path)\n",
    "print(f\"✅ 加载item_ids_list: {len(item_ids_list)}个items\")\n",
    "print(f\"   示例: {item_ids_list[:3]}\")\n",
    "item_to_position = {}\n",
    "for pos, item_id in enumerate(item_ids_list):\n",
    "    key = item_id.decode('utf-8') if isinstance(item_id, bytes) else str(item_id)\n",
    "    item_to_position[key] = pos\n",
    "df_all_merged['item_position'] = df_all_merged['item_id'].astype(str).map(\n",
    "    lambda x: item_to_position.get(x, 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ea3aff4-45b9-414d-9a27-8cc82a8a2472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dataset_type</th>\n",
       "      <th>sales_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>909658</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>11</td>\n",
       "      <td>1415</td>\n",
       "      <td>517</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>569610</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>11</td>\n",
       "      <td>1415</td>\n",
       "      <td>517</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>526039</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>11</td>\n",
       "      <td>1415</td>\n",
       "      <td>517</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id dataset_type  sales_type  brand  categories  label\n",
       "0   909658        0        train          11   1415         517      1\n",
       "1   569610        0        train          11   1415         517      0\n",
       "2   526039        0        train          11   1415         517      0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用labelencoder对稀疏特征进行编码\n",
    "encodered_columns = ['user_id', 'item_id', 'sales_type', 'brand','categories']\n",
    "lbe = LabelEncoder()\n",
    "for column in encodered_columns:\n",
    "    df_all_merged[column] = lbe.fit_transform(df_all_merged[column])\n",
    "columns = [col for col in df_all_merged.columns if col != 'label'] + ['label']\n",
    "df_all_merged = df_all_merged[columns]\n",
    "df_all_merged[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0730a5ad-a7ff-434b-8130-e60d743527b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.csv saved\n",
      "valid.csv saved\n",
      "test.csv saved\n"
     ]
    }
   ],
   "source": [
    "# 保存为csv和h5\n",
    "for dataset_type in dataset_types: \n",
    "    df_split = df_all_merged[df_all_merged['dataset_type'] == dataset_type].drop(columns=['dataset_type'])\n",
    "    output_path = f\"{output_root}/base_dataset\"\n",
    "    os.makedirs(output_path,exist_ok = True)\n",
    "    df_split.to_csv(os.path.join(output_path,f'{dataset_type}.csv'),index=False)\n",
    "    print(f\"{dataset_type}.csv saved\")\n",
    "    # with h5py.File(os.path.join(output_path,f'{dataset_type}.h5'), 'w') as f:\n",
    "    #     f.create_dataset('data', data=df_split.values,dtype='float64')\n",
    "    # print(f\"{dataset_type}.h5 saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667fb755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c0b9068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 加载item_ids_list: 56657个items\n",
      "   示例: ['0375829695', '0439855896', '0439893577']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_936137/3315848356.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  item_ids_list = torch.load(item_ids_path)\n"
     ]
    }
   ],
   "source": [
    "item_ids_path = os.path.join(data_root, \"item_id.pt\")\n",
    "item_ids_list = torch.load(item_ids_path)\n",
    "print(f\"✅ 加载item_ids_list: {len(item_ids_list)}个items\")\n",
    "print(f\"   示例: {item_ids_list[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d0e4f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3091269/3708196371.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  index = torch.load(\"/data2/wangzhongren/taolin_project/dataset/toys-split/moc_cbsize256_cbdim32_scala7_epoch500_index.pt\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 74, 132, 206,  ..., 223, 252,  89],\n",
       "        [132,  87,  86,  ..., 207,  86,  87],\n",
       "        [147,   6,  62,  ...,  82, 167, 213],\n",
       "        ...,\n",
       "        [212, 159,  44,  ..., 146, 147, 179],\n",
       "        [162, 153,  50,  ...,  18, 217, 145],\n",
       "        [  3,  87,  60,  ..., 187,  86,  87]], device='cuda:7')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = torch.load(\"/data2/wangzhongren/taolin_project/dataset/toys-split/moc_cbsize256_cbdim32_scala7_epoch500_index.pt\")\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39d67d9-ecf9-4533-acd7-75844709e0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6e1a03-3e7a-496e-aea0-ebe5dd97060d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tencent_taolin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
